---
tags:
  - üìäEST
  - üìùNOT
cssclasses:
  - center-titles
---

# [[üìäEST üè´MPR 03 Variables Aleatorias.pdf|Unidad 3: Variables Aleatorias]]

## 1. Introducci√≥n a Variables Aleatorias

> [!info] ¬øQu√© es una variable aleatoria?
> Una **variable aleatoria** es una funci√≥n que asigna un valor num√©rico a cada resultado de un experimento aleatorio. Los **modelos te√≥ricos** de variables aleatorias permiten calcular probabilidades de manera m√°s eficiente mediante f√≥rmulas y propiedades matem√°ticas, en lugar de enumerar todos los resultados posibles.

> [!quote] Definici√≥n formal
> Una variable aleatoria $X$ es una funci√≥n $X: S \to \mathbb{R}$ que asocia un n√∫mero real a cada elemento del espacio muestral $S$.

> [!example] Ejemplo
> Lanzamiento de 2 monedas $\Omega = {cc, cs, sc, ss}$ Evento: Obtener cara $X$: N√∫mero de caras obtenidas $X(cc) = 2$, $X(cs) = 1$, $X(sc) = 1$, $X(ss) = 0$

> [!question] Pregunta clave sobre definiciones **¬øQu√© expresiones son correctas para una V.A.D.?**
> - ‚úÖ $F(x) = P(X \leq x)$ (Funci√≥n de Distribuci√≥n Acumulada - CDF)
> - ‚úÖ $f(x) = P(X = x)$ (Funci√≥n de Probabilidad - PMF)

---

## 2. Funci√≥n de Probabilidad para Variables Aleatorias Discretas

> [!info] Funci√≥n de probabilidad $p(x)$
> Para una variable aleatoria discreta $X$, la **funci√≥n de probabilidad** (tambi√©n llamada funci√≥n de masa de probabilidad o PMF) $p(x)$ se define como:
> 
> $$p(x) = P(X = x)$$
> 
> Esta funci√≥n debe cumplir con dos propiedades fundamentales:
> 
> 1. $p(x) \geq 0$ para todo $x$ (las probabilidades no pueden ser negativas)
> 2. $\sum_{\text{todos los } x} p(x) = 1$ (la suma de todas las probabilidades debe ser 1)

| $x$    | 0     | 1     | 2     | 3     |
| ------ | ----- | ----- | ----- | ----- |
| $p(x)$ | 0.125 | 0.375 | 0.375 | 0.125 |

> [!warning] Propiedades importantes de f(x) y F(x)
> **¬øQu√© puede tomar valores negativos?**
> 
> - ‚ùå $f(x)$ NO puede ser negativa (es una probabilidad)
> - ‚ùå $F(x)$ NO puede ser negativa (es una probabilidad acumulada, va de 0 a 1)
> - ‚úÖ $E(X)$ S√ç puede ser negativo (si X toma valores negativos con mayor ponderaci√≥n)
> - ‚ùå $Var(X)$ NO puede ser negativa (es una suma de cuadrados ponderados, siempre $\geq 0$)

---

## 3. Funci√≥n de Distribuci√≥n Acumulada

> [!info] Definici√≥n
> Sea $X$ una variable aleatoria discreta. La **funci√≥n de distribuci√≥n acumulada** (CDF) $F(x)$ representa la probabilidad de que la variable aleatoria tome un valor menor o igual a $x$:
> 
> $$F(x) = P(X \leq x) = \sum_{t \leq x} f(t)$$
> 
> Esta funci√≥n acumula las probabilidades desde el valor m√°s peque√±o hasta $x$.

| $x$    | 0     | 1   | 2     | 3   |
| ------ | ----- | --- | ----- | --- |
| $F(x)$ | 0.125 | 0.5 | 0.875 | 1   |

---

## 4. Valor Esperado y Varianza

### 4.1 Valor Esperado

> [!info] Definici√≥n
> Sea $X$ una variable aleatoria discreta, el **valor esperado** (o esperanza matem√°tica) representa el promedio ponderado de todos los valores posibles de $X$:
> 
> $$E(X) = \mu_x = \sum_{\text{todos los } x} x \cdot p(x)$$
> 
> El valor esperado es el centro de masa de la distribuci√≥n de probabilidad.

> [!info] Valor esperado de funciones
> Para cualquier funci√≥n $g(X)$ de la variable aleatoria:
> 
> $$E[g(X)] = \sum_{\text{todos los } x} g(x) \cdot p(x)$$
> 
> Esta es la **Ley del Estad√≠stico Inconsciente**, que permite calcular la esperanza de transformaciones de $X$ sin necesidad de encontrar primero la distribuci√≥n de $g(X)$.

> [!success] Confirmaci√≥n te√≥rica
> **¬øEs correcta la expresi√≥n $E(g(x)) = \sum g(x)f(x)$?** ‚úÖ S√ç, es la definici√≥n correcta del Valor Esperado de una funci√≥n $g(X)$ de una variable aleatoria discreta $X$.

### 4.2 Varianza

> [!info] Definici√≥n
> La **varianza** de $X$ mide la dispersi√≥n o variabilidad de los valores de la variable aleatoria respecto a su media:
> 
> $$Var(X) = \sigma_x^2 = \sum_{\text{todos los } x} (x - \mu)^2 p(x)$$
> 
> Tambi√©n puede calcularse usando la f√≥rmula alternativa: $$Var(X) = E(X^2) - [E(X)]^2$$

> [!example] Ejemplo de c√°lculo de varianza

| $x$ | $p(x)$ | $(x - \mu)^2$ | $(x - \mu)^2 \cdot p(x)$ |
| --- | ------ | ------------- | ------------------------ |
| 0   | 0.125  | 2.25          | 0.28125                  |
| 1   | 0.375  | 0.25          | 0.09375                  |
| 2   | 0.375  | 0.25          | 0.09375                  |
| 3   | 0.125  | 2.25          | 0.28125                  |

$$Var(X) = 0.75$$

> [!warning] Error com√∫n sobre varianza
> **¬øEs correcto que $Var(aX+c) = a Var(X) + c$?** ‚ùå NO, la f√≥rmula correcta es: $$Var(aX+c) = a^2 Var(X)$$
> 
> - La constante aditiva $c$ NO afecta la dispersi√≥n (solo desplaza la distribuci√≥n)
> - El factor multiplicativo $a$ se eleva al cuadrado porque la varianza mide desviaciones cuadr√°ticas

---

## 5. Propiedades del Valor Esperado y Varianza

> [!success] Propiedades clave

| Concepto                          | F√≥rmula                      | Explicaci√≥n                                                  |
| --------------------------------- | ---------------------------- | ------------------------------------------------------------ |
| Esperanza de constante            | $E(c) = c$                   | El valor esperado de una constante es la constante misma     |
| Varianza de constante             | $Var(c) = 0$                 | Una constante no tiene variabilidad                          |
| Esperanza de constante √ó variable | $E(cX) = cE(X)$              | La esperanza es un operador lineal                           |
| Varianza de constante √ó variable  | $Var(cX) = c^2 Var(X)$       | La varianza escala con el cuadrado del factor multiplicativo |
| F√≥rmula alternativa de varianza   | $Var(X) = E(X^2) - [E(X)]^2$ | √ötil para c√°lculos pr√°cticos                                 |

> [!info] Propiedades adicionales de Esperanza
> 
> - Si $X \geq 0$ entonces $E(X) \geq 0$ (monotonicidad)
> - $E(X + Y) = E(X) + E(Y)$ (linealidad, v√°lida siempre, incluso si no son independientes)
> - $E(aX + b) = aE(X) + b$ (transformaci√≥n lineal)

> [!info] Propiedades adicionales de Varianza
> 
> - $Var(X) \geq 0$ (siempre no negativa)
> - $Var(X + c) = Var(X)$ (las constantes aditivas no afectan la varianza)
> - $Var(X + Y) = Var(X) + Var(Y)$ SOLO si $X$ e $Y$ son independientes
> - En general: $Var(X + Y) = Var(X) + Var(Y) + 2Cov(X,Y)$

> [!example] Aplicaci√≥n pr√°ctica: Juego de monedas
> **Problema**: Lanzar 3 monedas. Ganar $15 por 3 sellos o 3 caras, $8 por 2 sellos, perder $10 por 1 sello.
> 
> **Soluci√≥n**:
> 
> - $P(\text{3 sellos o 3 caras}) = \frac{2}{8}$
> - $P(\text{2 sellos}) = \frac{3}{8}$
> - $P(\text{1 sello}) = \frac{3}{8}$
> 
> $$E(X) = (15) \cdot \frac{2}{8} + (8) \cdot \frac{3}{8} + (-10) \cdot \frac{3}{8} = 3$$ ‚úÖ Se espera ganar $3 en promedio por juego.

---

## 6. Principales Modelos Discretos

### 6.1 Distribuci√≥n Binomial

> [!success] Descripci√≥n  
> La distribuci√≥n binomial permite calcular la probabilidad de obtener un n√∫mero espec√≠fico de √©xitos en $n$ ensayos o experimentos independientes, donde cada ensayo tiene exactamente dos resultados posibles (√©xito o fracaso) y la probabilidad de √©xito $p$ permanece constante en todos los ensayos.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim B(n, p)$ o $X \sim Bin(n, p)$
> - Cuenta el n√∫mero de √©xitos en $n$ intentos independientes
> - Funci√≥n de probabilidad: $P(X = x) = \binom{n}{x} p^x (1-p)^{n-x}$ para $x = 0, 1, 2, \ldots, n$
> - Valor esperado: $E(X) = np$
> - Varianza: $Var(X) = np(1-p) = npq$ donde $q = 1-p$

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n binomial, se necesita:
> 
> - **$n$**: N√∫mero fijo de ensayos o intentos
> - **$p$**: Probabilidad de √©xito en cada ensayo (constante)
> - **$x$**: N√∫mero de √©xitos que se desea calcular (entre 0 y $n$)
> 
> Adem√°s, debe verificarse que:
> 
> - Los ensayos sean independientes entre s√≠
> - Cada ensayo tenga solo dos resultados posibles
> - La probabilidad de √©xito sea la misma en todos los ensayos

> [!success] Caracter√≠sticas de un experimento binomial
> ‚úÖ **Requisitos que deben cumplirse**:
> 
> - El experimento consiste en $n$ repeticiones o intentos id√©nticos
> - Cada intento es independiente de los dem√°s
> - Cada intento solo puede resultar en √©xito o fracaso
> - La probabilidad de √©xito $p$ es constante en todos los intentos
> - La variable de inter√©s es el n√∫mero total de √©xitos en los $n$ intentos

> [!example] C√°lculo binomial
> **Problema**: Una f√°brica produce piezas con 5% de defectuosas. Si se seleccionan 10 piezas al azar (con reemplazo), ¬øcu√°l es la probabilidad de encontrar exactamente 2 defectuosas?
> 
> **Soluci√≥n**: $n = 10$, $p = 0.05$, $x = 2$ $$P(X=2) = \binom{10}{2} (0.05)^2 (0.95)^8 = 45 \times 0.0025 \times 0.6634 \approx 0.0746$$

> [!example] Ejemplo aplicado
> **Problema**: Si la probabilidad de que un paciente se recupere de una enfermedad es 0.40, ¬øcu√°l es la probabilidad de que exactamente 7 de 10 pacientes se recuperen?
> 
> **Soluci√≥n**: $n = 10$, $p = 0.40$, $x = 7$ $$P(X=7) = \binom{10}{7} (0.40)^7 (0.60)^3 = 120 \times 0.0016384 \times 0.216 \approx 0.0425$$

### 6.2 Distribuci√≥n Binomial Negativa

> [!success] Descripci√≥n  
> La distribuci√≥n binomial negativa permite calcular la probabilidad de que se necesiten exactamente $x$ ensayos para obtener el $k$-√©simo √©xito, en una secuencia de ensayos independientes donde cada uno tiene probabilidad constante $p$ de √©xito. A diferencia de la binomial, aqu√≠ el n√∫mero de ensayos es variable y lo que se fija es el n√∫mero de √©xitos deseados.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim BN(k, p)$ o $X \sim NB(k, p)$
> - Cuenta el n√∫mero de ensayos necesarios hasta obtener el $k$-√©simo √©xito
> - Funci√≥n de probabilidad: $P(X = x) = \binom{x-1}{k-1} p^k (1-p)^{x-k}$ para $x = k, k+1, k+2, \ldots$
> - Valor esperado: $E(X) = \frac{k}{p}$
> - Varianza: $Var(X) = \frac{k(1-p)}{p^2}$

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n binomial negativa, se necesita:
> 
> - **$k$**: N√∫mero de √©xitos que se desea alcanzar (fijo)
> - **$p$**: Probabilidad de √©xito en cada ensayo (constante)
> - **$x$**: N√∫mero total de ensayos en el cual ocurre el $k$-√©simo √©xito
> 
> Adem√°s, debe verificarse que:
> 
> - Los ensayos sean independientes entre s√≠
> - La probabilidad de √©xito sea constante
> - Se contin√∫a hasta lograr exactamente $k$ √©xitos

> [!example] Aplicaci√≥n pr√°ctica
> **Problema**: En un lote con 5% de piezas defectuosas, si se inspeccionan piezas una por una (con reemplazo), ¬øcu√°l es la probabilidad de necesitar 5 o m√°s inspecciones para encontrar 3 piezas defectuosas?
> 
> **Soluci√≥n**: $k = 3$, $p = 0.05$ $$P(X \geq 5) = 1 - [P(X=3) + P(X=4)]$$ $$P(X=3) = \binom{2}{2}(0.05)^3(0.95)^0 = 0.000125$$ $$P(X=4) = \binom{3}{2}(0.05)^3(0.95)^1 = 0.000356$$ $$P(X \geq 5) \approx 0.9995$$

> [!example] Ejemplo aplicado
> **Problema**: Si la probabilidad de √©xito en cada intento es 20%, ¬øcu√°l es la probabilidad de necesitar exactamente 10 intentos para lograr 3 √©xitos?
> 
> **Soluci√≥n**: $k = 3$, $p = 0.20$, $x = 10$ $$P(X=10) = \binom{9}{2} (0.20)^3 (0.80)^7 = 36 \times 0.008 \times 0.2097 \approx 0.0605$$

### 6.3 Distribuci√≥n Geom√©trica

> [!success] Descripci√≥n  
> La distribuci√≥n geom√©trica permite calcular la probabilidad de que el primer √©xito ocurra en el $x$-√©simo ensayo, en una secuencia de ensayos independientes con probabilidad constante $p$ de √©xito. Es un caso especial de la binomial negativa cuando $k=1$ (buscamos solo el primer √©xito).

> [!tip] Caso especial
> Es un caso particular de la binomial negativa cuando $k = 1$:
> 
> - Funci√≥n de probabilidad: $P(X = x) = p(1-p)^{x-1}$ para $x = 1, 2, 3, \ldots$
> - Valor esperado: $E(X) = \frac{1}{p}$
> - Varianza: $Var(X) = \frac{1-p}{p^2}$

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n geom√©trica, se necesita:
> 
> - **$p$**: Probabilidad de √©xito en cada ensayo (constante)
> - **$x$**: N√∫mero del ensayo en el cual ocurre el primer √©xito
> 
> Adem√°s, debe verificarse que:
> 
> - Los ensayos sean independientes entre s√≠
> - La probabilidad de √©xito sea constante
> - Se busca √∫nicamente el primer √©xito

> [!question] Relaci√≥n entre distribuciones
> **¬øLa binomial es caso particular de la geom√©trica cuando intentos=1?** ‚ùå NO. La binomial con $n=1$ es una distribuci√≥n de Bernoulli (un solo ensayo con √©xito/fracaso), no una distribuci√≥n geom√©trica. La geom√©trica cuenta el n√∫mero de ensayos hasta el primer √©xito, que puede ser cualquier n√∫mero $\geq 1$.

> [!example] Identificaci√≥n de distribuci√≥n
> **Problema**: En un proceso con 20% de productos defectuosos, ¬øcu√°l es la probabilidad de que la primera pieza defectuosa se encuentre en la primera inspecci√≥n?
> 
> **Soluci√≥n**: ‚úÖ **Distribuci√≥n Geom√©trica** - se busca el primer √©xito $$P(X=1) = 0.20 \times (0.80)^0 = 0.20$$

> [!example] Ejemplo aplicado
> **Problema**: Si 15% de las piezas son defectuosas:
> 
> a) ¬øProbabilidad de que la primera pieza defectuosa aparezca en la quinta inspecci√≥n? $$P(X=5) = 0.15 \times (0.85)^4 = 0.15 \times 0.5220 \approx 0.0783$$
> 
> b) ¬øProbabilidad de no encontrar piezas defectuosas en las primeras 10 inspecciones? $$P(X > 10) = (0.85)^{10} \approx 0.1969$$

### 6.4 Distribuci√≥n de Poisson

> [!success] Descripci√≥n  
> La distribuci√≥n de Poisson permite calcular la probabilidad de que ocurra un n√∫mero espec√≠fico de eventos en un intervalo fijo de tiempo, espacio, √°rea o volumen, cuando estos eventos ocurren de manera independiente y con una tasa promedio constante conocida $\lambda$. Es especialmente √∫til para modelar eventos raros que ocurren de forma aleatoria.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim P(\lambda)$ o $X \sim Poisson(\lambda)$
> - Modela el n√∫mero de eventos que ocurren en una unidad fija de tiempo, √°rea o volumen
> - Funci√≥n de probabilidad: $P(X = x) = \frac{\lambda^x e^{-\lambda}}{x!}$ para $x = 0, 1, 2, \ldots$
> - Valor esperado: $E(X) = \lambda$
> - Varianza: $Var(X) = \lambda$
> - **Propiedad √∫nica**: La media y la varianza son iguales

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n de Poisson, se necesita:
> 
> - **$\lambda$**: Tasa promedio de ocurrencia de eventos por unidad (tiempo, √°rea, volumen, etc.)
> - **$x$**: N√∫mero de eventos que se desea calcular
> - **Unidad de medida**: Intervalo de tiempo, √°rea o volumen en el que se cuentan los eventos
> 
> Adem√°s, debe verificarse que:
> 
> - Los eventos ocurren de manera independiente
> - La tasa promedio $\lambda$ es constante
> - Los eventos son raros (baja probabilidad individual)
> - No pueden ocurrir dos eventos simult√°neamente en el mismo punto

> [!example] Ejemplo aplicado
> **Problema**: En un cultivo llegan en promedio 2 microorganismos pat√≥genos por hora. ¬øCu√°l es la probabilidad de observar hasta 3 microorganismos en una hora?
> 
> **Soluci√≥n**: $\lambda = 2$, calcular $P(X \leq 3)$ $$P(X \leq 3) = \sum_{x=0}^{3} \frac{e^{-2} \cdot 2^x}{x!} = e^{-2}\left(\frac{2^0}{0!} + \frac{2^1}{1!} + \frac{2^2}{2!} + \frac{2^3}{3!}\right)$$ $$= e^{-2}(1 + 2 + 2 + 1.333) = 0.1353 \times 6.333 \approx 0.857$$

### 6.5 Distribuci√≥n Hipergeom√©trica

> [!success] Descripci√≥n  
> La distribuci√≥n hipergeom√©trica permite calcular la probabilidad de obtener un n√∫mero espec√≠fico de √©xitos al extraer una muestra de tama√±o $n$ sin reemplazo de una poblaci√≥n finita de tama√±o $N$ que contiene $k$ elementos con la caracter√≠stica de inter√©s. A diferencia de la binomial, las extracciones NO son independientes porque no hay reemplazo, lo que hace que las probabilidades cambien en cada extracci√≥n.

> [!info] Identificaci√≥n de distribuci√≥n
> **Problema**: En un curso de 40 personas hay estudiantes de varias ingenier√≠as. Si se seleccionan 8 personas SIN reemplazo, ¬øcu√°l es la probabilidad de que 5 sean de ingenier√≠a mec√°nica?
> 
> ‚úÖ **Distribuci√≥n Hipergeom√©trica** - muestreo sin reemplazo de poblaci√≥n finita.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim H(N, n, k)$ o $X \sim Hypergeom(N, n, k)$
> - Modela el n√∫mero de √©xitos en una muestra de tama√±o $n$ extra√≠da sin reemplazo de una poblaci√≥n de tama√±o $N$
> - Funci√≥n de probabilidad: $P(X = x) = \frac{\binom{k}{x}\binom{N-k}{n-x}}{\binom{N}{n}}$
> - Valor esperado: $E(X) = \frac{nk}{N} = n \cdot \frac{k}{N}$
> - Varianza: $V(X) = \frac{N-n}{N-1} \cdot \frac{nk}{N}\left(1-\frac{k}{N}\right)$
> - El factor $\frac{N-n}{N-1}$ es el **factor de correcci√≥n por poblaci√≥n finita**

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n hipergeom√©trica, se necesita:
> 
> - **$N$**: Tama√±o total de la poblaci√≥n
> - **$k$**: N√∫mero de elementos en la poblaci√≥n con la caracter√≠stica de inter√©s (√©xitos)
> - **$n$**: Tama√±o de la muestra extra√≠da
> - **$x$**: N√∫mero de √©xitos deseados en la muestra
> 
> Adem√°s, debe verificarse que:
> 
> - El muestreo sea sin reemplazo
> - La poblaci√≥n sea finita
> - $x \leq \min(n, k)$ y $x \geq \max(0, n-(N-k))$

> [!example] Ejemplo aplicado
> **Problema**: En una poblaci√≥n de 1000 bacterias hay 150 resistentes a un antibi√≥tico. Si se toma una muestra de 100 bacterias, ¬øcu√°l es la probabilidad de obtener exactamente 10 resistentes?
> 
> **Soluci√≥n**: $N = 1000$, $k = 150$, $n = 100$, $x = 10$ $$P(X=10) = \frac{\binom{150}{10}\binom{850}{90}}{\binom{1000}{100}}$$
> 
> Este c√°lculo requiere software estad√≠stico para obtener el resultado num√©rico.

---

## 7. Variables Aleatorias Continuas

### 7.1 Definici√≥n y Funci√≥n de Densidad

> [!info] Definici√≥n
> Una variable aleatoria es **continua** cuando puede tomar cualquier valor dentro de un intervalo de n√∫meros reales. A diferencia de las discretas, las continuas no pueden enumerarse y tienen infinitos valores posibles en cualquier intervalo.

> [!info] Funci√≥n de densidad de probabilidad $f(x)$
> Sea $X$ una variable aleatoria continua. La funci√≥n $f(x): \mathbb{R} \to \mathbb{R}$ es la **funci√≥n de densidad de probabilidad** (PDF) de $X$ si cumple:
> 
> 1. $f(x) \geq 0$ para todo $x \in \mathbb{R}$ (no negatividad)
> 2. $\int_{-\infty}^{+\infty} f(x) , dx = 1$ (√°rea total igual a 1)
> 
> **Importante**: Para variables continuas, $P(X = x) = 0$ para cualquier valor espec√≠fico $x$. La probabilidad se calcula sobre intervalos:
> 
> $$P(a < X < b) = P(a \leq X \leq b) = \int_a^b f(x) , dx$$

### 7.2 Funci√≥n de Distribuci√≥n Acumulada

> [!info] Definici√≥n
> La funci√≥n de distribuci√≥n acumulada (CDF) para una variable aleatoria continua es:
> 
> $$F(x) = P(X \leq x) = \int_{-\infty}^{x} f(t) , dt$$
> 
> Esta funci√≥n acumula toda la probabilidad desde $-\infty$ hasta $x$.

> [!success] Propiedades importantes
> 
> - La densidad es la derivada de la CDF: $f(x) = \frac{d}{dx}F(x)$
> - $F(x)$ es una funci√≥n mon√≥tona no decreciente (siempre crece o se mantiene constante)
> - $F(x)$ es una funci√≥n continua
> - $\lim_{x \to -\infty} F(x) = 0$ y $\lim_{x \to +\infty} F(x) = 1$
> - $P(a < X < b) = F(b) - F(a)$

### 7.3 Valor Esperado y Varianza

> [!info] Definiciones para variables continuas
> Para una variable aleatoria continua $X$ con funci√≥n de densidad $f(x)$:
> 
> - **Valor esperado**: $E(X) = \mu = \int_{-\infty}^{+\infty} x \cdot f(x) , dx$
> - **Varianza**: $Var(X) = \sigma^2 = \int_{-\infty}^{+\infty} (x - \mu)^2 f(x) , dx$
> - **F√≥rmula alternativa**: $Var(X) = E(X^2) - [E(X)]^2$
> - **Esperanza de funciones**: $E(g(X)) = \int_{-\infty}^{+\infty} g(x) \cdot f(x) , dx$

---

## 8. Principales Modelos Continuos

### 8.1 Distribuci√≥n Uniforme

> [!success] Descripci√≥n
> La distribuci√≥n uniforme continua modela situaciones donde todos los valores en un intervalo $[a, b]$ tienen la misma probabilidad de ocurrir. La probabilidad es "uniforme" o constante en todo el intervalo. Es √∫til cuando no hay raz√≥n para favorecer ning√∫n valor sobre otro dentro del rango.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim U(a,b)$ o $X \sim Uniform(a,b)$
> - Probabilidad uniforme en el intervalo $[a, b]$
> - Funci√≥n de densidad: $$f(x) = \begin{cases} \frac{1}{b-a} & \text{si } a \leq x \leq b \ 0 & \text{en otro caso} \end{cases}$$
> - Funci√≥n de distribuci√≥n: $$F(x) = \begin{cases} 0 & \text{si } x < a \ \frac{x-a}{b-a} & \text{si } a \leq x \leq b \ 1 & \text{si } x > b \end{cases}$$
> - Valor esperado: $E(X) = \frac{a+b}{2}$ (punto medio del intervalo)
> - Varianza: $Var(X) = \frac{(b-a)^2}{12}$

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n uniforme, se necesita:
> 
> - **$a$**: L√≠mite inferior del intervalo
> - **$b$**: L√≠mite superior del intervalo (con $b > a$)
> 
> Debe verificarse que:
> 
> - Todos los valores en $[a, b]$ sean igualmente probables
> - No haya informaci√≥n que favorezca ning√∫n valor sobre otro

> [!example] Ejemplo aplicado
> **Problema**: El tiempo de metabolizaci√≥n de un medicamento en el cuerpo est√° uniformemente distribuido entre 2 y 6 horas. ¬øCu√°l es la probabilidad de que la metabolizaci√≥n ocurra entre 3 y 4 horas?
> 
> **Soluci√≥n**: $a = 2$, $b = 6$ $$P(3 < X < 4) = \frac{4-3}{6-2} = \frac{1}{4} = 0.25$$
> 
> Tambi√©n: $E(X) = \frac{2+6}{2} = 4$ horas (tiempo promedio de metabolizaci√≥n)

### 8.2 Distribuci√≥n Normal

> [!success] Descripci√≥n
> La distribuci√≥n normal (o gaussiana) es la distribuci√≥n continua m√°s importante en estad√≠stica. Modela fen√≥menos naturales y mediciones que tienden a concentrarse alrededor de un valor central (la media), con desviaciones sim√©tricas hacia ambos lados. Es fundamental en inferencia estad√≠stica por el Teorema del L√≠mite Central, que establece que las sumas y promedios de muchas variables tienden a seguir una distribuci√≥n normal.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim N(\mu, \sigma)$ o $X \sim Normal(\mu, \sigma^2)$
> - Funci√≥n de densidad: $$f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}, \quad x \in \mathbb{R}$$
> - Curva sim√©trica respecto a la media $\mu$ (forma de campana)
> - Valor esperado: $E(X) = \mu$
> - Varianza: $Var(X) = \sigma^2$
> - Desviaci√≥n est√°ndar: $\sigma$
> - √Årea total bajo la curva = 1
> - Aproximadamente 68% de los datos est√°n dentro de $\mu \pm \sigma$
> - Aproximadamente 95% de los datos est√°n dentro de $\mu \pm 2\sigma$
> - Aproximadamente 99.7% de los datos est√°n dentro de $\mu \pm 3\sigma$ (Regla emp√≠rica)

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n normal, se necesita:
> 
> - **$\mu$**: Media o valor esperado de la distribuci√≥n
> - **$\sigma$**: Desviaci√≥n est√°ndar (con $\sigma > 0$)
> - **$\sigma^2$**: Varianza (a veces se proporciona en lugar de $\sigma$)
> 
> Para calcular probabilidades, tambi√©n se necesita:
> 
> - Los valores o intervalo de inter√©s para calcular $P(a < X < b)$

> [!example] Ejemplo aplicado
> **Problema**: La concentraci√≥n de una toxina en muestras de agua sigue una distribuci√≥n $N(10, 2)$ ¬µg/ml. ¬øCu√°l es la probabilidad de que una muestra tenga concentraci√≥n entre 8 y 12 ¬µg/ml?
> 
> **Soluci√≥n**: $\mu = 10$, $\sigma = 2$
> 
> Estandarizamos: $$Z_1 = \frac{8-10}{2} = -1, \quad Z_2 = \frac{12-10}{2} = 1$$ $$P(8 < X < 12) = P(-1 < Z < 1) \approx 0.6827$$
> 
> Interpretaci√≥n: Aproximadamente 68.27% de las muestras tendr√°n concentraciones entre 8 y 12 ¬µg/ml.

### 8.3 Distribuci√≥n Normal Est√°ndar

> [!success] Descripci√≥n
> La distribuci√≥n normal est√°ndar es un caso especial de la distribuci√≥n normal con media 0 y desviaci√≥n est√°ndar 1. Es fundamental porque cualquier variable con distribuci√≥n normal puede transformarse a una normal est√°ndar mediante estandarizaci√≥n, lo que permite usar tablas de probabilidades universales.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $Z \sim N(0, 1)$
> - **Transformaci√≥n de estandarizaci√≥n**: Si $X \sim N(\mu, \sigma)$, entonces $Z = \frac{X-\mu}{\sigma} \sim N(0, 1)$
> - Funci√≥n de densidad: $$f(z) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}}, \quad z \in \mathbb{R}$$
> - Valor esperado: $E(Z) = 0$
> - Varianza: $Var(Z) = 1$
> - Sim√©trica respecto a $z = 0$
> - Se utilizan tablas o software para calcular probabilidades

> [!info] Requisitos / Datos necesarios
> Para usar la normal est√°ndar, se necesita:
> 
> - La **puntuaci√≥n z** o valor estandarizado
> - Si se parte de $X \sim N(\mu, \sigma)$: los valores de $\mu$, $\sigma$ y el valor $x$ a estandarizar
> 
> **F√≥rmula de estandarizaci√≥n**: $z = \frac{x - \mu}{\sigma}$

> [!tip] Uso pr√°ctico
> Para calcular $P(a < X < b)$ cuando $X \sim N(\mu, \sigma)$:
> 
> 1. Estandarizar: $z_1 = \frac{a-\mu}{\sigma}$ y $z_2 = \frac{b-\mu}{\sigma}$
> 2. Calcular: $P(a < X < b) = P(z_1 < Z < z_2) = \Phi(z_2) - \Phi(z_1)$
> 
> donde $\Phi(z)$ es la funci√≥n de distribuci√≥n acumulada de $Z$.

### 8.4 Distribuci√≥n t-Student

> [!success] Descripci√≥n
> La distribuci√≥n t-Student es una distribuci√≥n continua sim√©trica similar a la normal pero con colas m√°s pesadas (mayor probabilidad en los extremos). Es fundamental en inferencia estad√≠stica cuando se trabaja con muestras peque√±as y la desviaci√≥n est√°ndar poblacional es desconocida. A medida que aumenta el tama√±o de muestra, se aproxima a la normal est√°ndar.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $T \sim t(v)$ o $T \sim t_{v}$
> - Par√°metro: **grados de libertad** $v$ (usualmente $v = n - 1$ donde $n$ es el tama√±o de muestra)
> - Sim√©trica y centrada en 0, como la normal est√°ndar
> - Colas m√°s pesadas que la normal (mayor variabilidad)
> - Cuando $v \to \infty$, entonces $t_v \to N(0,1)$
> - Para $v > 30$, la distribuci√≥n t es muy similar a la normal est√°ndar
> - Valor esperado: $E(T) = 0$ (para $v > 1$)
> - Varianza: $Var(T) = \frac{v}{v-2}$ (para $v > 2$)

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n t-Student, se necesita:
> 
> - **$v$**: Grados de libertad (t√≠picamente $v = n - 1$ donde $n$ es el tama√±o de muestra)
> - El **valor cr√≠tico** $t$ o el intervalo de inter√©s
> 
> Se usa principalmente en:
> 
> - Pruebas de hip√≥tesis para medias con $\sigma$ desconocida
> - Intervalos de confianza para medias
> - Comparaci√≥n de dos medias

### 8.5 Distribuci√≥n Exponencial

> [!success] Descripci√≥n
> La distribuci√≥n exponencial modela el tiempo de espera hasta que ocurre un evento en un proceso de Poisson. Es la distribuci√≥n continua del tiempo entre eventos consecutivos cuando los eventos ocurren de manera aleatoria e independiente con una tasa constante. Tiene la propiedad de "falta de memoria": la probabilidad de que ocurra un evento en el pr√≥ximo intervalo no depende del tiempo ya transcurrido.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim Exp(\beta)$ o $X \sim Exp(\lambda)$
> - Funci√≥n de densidad (parametrizaci√≥n con $\beta$): $$f(x) = \begin{cases} \frac{1}{\beta} e^{-x/\beta} & \text{si } x > 0 \ 0 & \text{en otro caso} \end{cases}$$
> - Funci√≥n de densidad (parametrizaci√≥n con $\lambda$): $$f(x) = \begin{cases} \lambda e^{-\lambda x} & \text{si } x > 0 \ 0 & \text{en otro caso} \end{cases}$$
> - Funci√≥n de distribuci√≥n: $F(x) = 1 - e^{-\lambda x} = 1 - e^{-x/\beta}$ para $x > 0$
> - Valor esperado: $E(X) = \beta = \frac{1}{\lambda}$
> - Varianza: $Var(X) = \beta^2 = \frac{1}{\lambda^2}$

> [!info] Relaci√≥n con Poisson
> **Conexi√≥n importante**: Si el n√∫mero de eventos por unidad de tiempo sigue una distribuci√≥n de Poisson con par√°metro $\lambda$, entonces el tiempo entre eventos consecutivos sigue una distribuci√≥n Exponencial con par√°metro $\lambda$.
> 
> - Poisson cuenta **cu√°ntos eventos** ocurren en un tiempo fijo
> - Exponencial mide **cu√°nto tiempo** hasta el pr√≥ximo evento

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n exponencial, se necesita:
> 
> - **$\lambda$**: Tasa de ocurrencia de eventos por unidad de tiempo (eventos/tiempo)
> - O alternativamente **$\beta = \frac{1}{\lambda}$**: Tiempo promedio entre eventos
> - **$x$ o intervalo**: El tiempo de inter√©s para calcular probabilidades
> 
> Debe verificarse que:
> 
> - Los eventos ocurren de manera continua e independiente
> - La tasa de ocurrencia es constante
> - El proceso no tiene memoria

> [!example] Ejemplo aplicado
> **Problema**: Las bacterias en un cultivo mueren a una tasa de 0.25 por hora. ¬øCu√°l es la probabilidad de que una bacteria sobreviva menos de 3 horas?
> 
> **Soluci√≥n**: $\lambda = 0.25$ por hora, calcular $P(X < 3)$ $$P(X < 3) = 1 - e^{-0.25 \times 3} = 1 - e^{-0.75} = 1 - 0.4724 \approx 0.5276$$
> 
> Interpretaci√≥n: Aproximadamente 52.76% de las bacterias mueren antes de las 3 horas.
> 
> Tiempo promedio de supervivencia: $E(X) = \frac{1}{0.25} = 4$ horas.

### 8.6 Distribuci√≥n Gamma

> [!success] Descripci√≥n
> La distribuci√≥n Gamma es una familia flexible de distribuciones continuas que generaliza la distribuci√≥n exponencial. Modela el tiempo de espera hasta que ocurren $\alpha$ eventos en un proceso de Poisson, o la suma de $\alpha$ variables exponenciales independientes. Es √∫til en an√°lisis de confiabilidad, teor√≠a de colas y modelado de tiempos de espera.

> [!info] Funci√≥n Gamma
> La **funci√≥n Gamma** $\Gamma(\alpha)$ es una generalizaci√≥n del factorial para n√∫meros reales:
> 
> $$\Gamma(\alpha) = \int_{0}^{\infty} x^{\alpha-1} e^{-x} , dx, \quad \alpha > 0$$
> 
> **Propiedades importantes**:
> 
> - $\Gamma(\alpha) = (\alpha-1)\Gamma(\alpha-1)$ (propiedad recursiva)
> - Si $n$ es un entero positivo: $\Gamma(n) = (n-1)!$
> - $\Gamma(1) = 1$
> - $\Gamma(1/2) = \sqrt{\pi}$

> [!info] Distribuci√≥n Gamma
> 
> - Notaci√≥n: $X \sim Gamma(\alpha, \beta)$
> - Par√°metros: $\alpha > 0$ (forma), $\beta > 0$ (escala)
> - Funci√≥n de densidad: $$f(x) = \begin{cases} \frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha-1} e^{-x/\beta} & \text{si } x > 0 \ 0 & \text{en otro caso} \end{cases}$$
> - Valor esperado: $E(X) = \alpha\beta$
> - Varianza: $Var(X) = \alpha\beta^2$
> - Cuando $\alpha = 1$: se reduce a la distribuci√≥n Exponencial($\beta$)

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n Gamma, se necesita:
> 
> - **$\alpha$**: Par√°metro de forma (n√∫mero de eventos, si se modela un proceso de Poisson)
> - **$\beta$**: Par√°metro de escala (tiempo promedio entre eventos)
> 
> Interpretaci√≥n: Si los eventos ocurren seg√∫n un proceso de Poisson, Gamma($\alpha$, $\beta$) modela el tiempo hasta el $\alpha$-√©simo evento.

### 8.7 Distribuci√≥n Chi-cuadrado

> [!success] Descripci√≥n
> La distribuci√≥n Chi-cuadrado ($\chi^2$) es un caso especial de la distribuci√≥n Gamma y es fundamental en inferencia estad√≠stica. Se usa en pruebas de bondad de ajuste, pruebas de independencia, y en la construcci√≥n de intervalos de confianza para varianzas. Si $Z_1, Z_2, \ldots, Z_v$ son variables normales est√°ndar independientes, entonces $\sum_{i=1}^{v} Z_i^2$ sigue una distribuci√≥n $\chi^2$ con $v$ grados de libertad.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim \chi^2(v)$ o $X \sim \chi^2_{v}$
> - Par√°metro: **grados de libertad** $v$ (entero positivo)
> - Caso especial de Gamma con $\alpha = \frac{v}{2}$ y $\beta = 2$
> - Funci√≥n de densidad: $$f(x) = \begin{cases} \frac{1}{2^{v/2}\Gamma(v/2)} x^{v/2-1} e^{-x/2} & \text{si } x > 0 \ 0 & \text{en otro caso} \end{cases}$$
> - Valor esperado: $E(X) = v$
> - Varianza: $Var(X) = 2v$
> - La distribuci√≥n es asim√©trica positiva (sesgada a la derecha)
> - A medida que $v$ aumenta, se aproxima a la normal

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n Chi-cuadrado, se necesita:
> 
> - **$v$**: Grados de libertad
> 
> Se usa com√∫nmente en:
> 
> - Pruebas de bondad de ajuste
> - Pruebas de independencia en tablas de contingencia
> - Intervalos de confianza para varianzas
> - Estad√≠stico: $\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}$ donde $O_i$ son frecuencias observadas y $E_i$ esperadas

### 8.8 Distribuci√≥n Weibull

> [!success] Descripci√≥n
> La distribuci√≥n Weibull es una distribuci√≥n continua muy vers√°til usada principalmente en an√°lisis de confiabilidad, estudios de vida √∫til de materiales y componentes, y modelado de tasas de falla. Puede modelar tanto tasas de falla crecientes, decrecientes o constantes dependiendo del par√°metro de forma, lo que la hace muy √∫til en ingenier√≠a y control de calidad.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim Weibull(\alpha, \beta)$
> - Par√°metros: $\alpha > 0$ (escala), $\beta > 0$ (forma)
> - Funci√≥n de densidad: $$f(x) = \begin{cases} \alpha\beta x^{\beta-1} e^{-\alpha x^\beta} & \text{si } x > 0 \ 0 & \text{en otro caso} \end{cases}$$
> - Cuando $\beta = 1$: se reduce a la distribuci√≥n Exponencial
> - Cuando $\beta < 1$: tasa de falla decreciente (mortalidad infantil)
> - Cuando $\beta = 1$: tasa de falla constante
> - Cuando $\beta > 1$: tasa de falla creciente (desgaste)

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n Weibull, se necesita:
> 
> - **$\alpha$**: Par√°metro de escala ($\alpha > 0$)
> - **$\beta$**: Par√°metro de forma ($\beta > 0$)
> 
> Se usa principalmente en:
> 
> - An√°lisis de confiabilidad de componentes
> - Estudios de vida √∫til
> - Modelado de tiempos de falla
> - An√°lisis de supervivencia

### 8.9 Distribuci√≥n Beta

> [!success] Descripci√≥n
> La distribuci√≥n Beta es una familia de distribuciones continuas definidas en el intervalo [0, 1], lo que la hace ideal para modelar proporciones, probabilidades y tasas. Es extremadamente flexible y puede tomar formas muy diversas (uniforme, en forma de U, en forma de campana, sesgada) dependiendo de sus par√°metros, por lo que es √∫til en an√°lisis bayesiano y modelado de incertidumbre.

> [!info] Caracter√≠sticas
> 
> - Notaci√≥n: $X \sim Beta(\alpha, \beta)$
> - Par√°metros: $\alpha > 0$, $\beta > 0$ (ambos de forma)
> - Dominio: $0 < x < 1$ (solo toma valores entre 0 y 1)
> - Funci√≥n de densidad: $$f(x) = \begin{cases} \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1} & \text{si } 0 < x < 1 \ 0 & \text{en otro caso} \end{cases}$$
> - Valor esperado: $E(X) = \frac{\alpha}{\alpha+\beta}$
> - Varianza: $Var(X) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$
> - Cuando $\alpha = \beta = 1$: se reduce a la distribuci√≥n Uniforme(0, 1)
> - Cuando $\alpha = \beta$: la distribuci√≥n es sim√©trica

> [!info] Requisitos / Datos necesarios
> Para aplicar la distribuci√≥n Beta, se necesita:
> 
> - **$\alpha$**: Primer par√°metro de forma ($\alpha > 0$)
> - **$\beta$**: Segundo par√°metro de forma ($\beta > 0$)
> 
> Se usa com√∫nmente para modelar:
> 
> - Proporciones o porcentajes
> - Probabilidades
> - Tasas de √©xito o supervivencia
> - Variables que est√°n naturalmente acotadas entre 0 y 1

> [!example] Ejemplo aplicado
> **Problema**: La tasa de supervivencia de bacterias tras un tratamiento sigue una distribuci√≥n Beta(2, 5). ¬øCu√°l es la probabilidad de que la tasa de supervivencia sea mayor al 20%?
> 
> **Soluci√≥n**: $\alpha = 2$, $\beta = 5$, calcular $P(X > 0.20)$ $$P(X > 0.20) = \int_{0.20}^{1} \frac{\Gamma(7)}{\Gamma(2)\Gamma(5)} x^{1}(1-x)^{4} , dx$$
> 
> Este c√°lculo requiere integraci√≥n num√©rica o software estad√≠stico.
> 
> Tasa promedio de supervivencia: $E(X) = \frac{2}{2+5} = \frac{2}{7} \approx 0.286$ o 28.6%

---

## 9. Distribuciones Conjuntas

### 9.1 Caso Discreto

> [!info] Definici√≥n
> Sean $X$ e $Y$ dos variables aleatorias discretas. La funci√≥n $f(x,y)$ es una **distribuci√≥n de probabilidad conjunta** si cumple:
> 
> 1. $f(x,y) \geq 0$ para todo par $(x,y)$ (no negatividad)
> 2. $\sum_{x} \sum_{y} f(x,y) = 1$ (suma total igual a 1)
> 3. $P(X=x, Y=y) = f(x,y)$ (probabilidad del evento conjunto)
> 
> La funci√≥n conjunta describe la probabilidad de que $X$ tome el valor $x$ **y simult√°neamente** $Y$ tome el valor $y$.

### 9.2 Caso Continuo

> [!info] Definici√≥n
> Sean $X$ e $Y$ dos variables aleatorias continuas. La funci√≥n $f(x,y)$ es una **distribuci√≥n de densidad conjunta** si cumple:
> 
> 1. $f(x,y) \geq 0$ para todo par $(x,y)$ (no negatividad)
> 2. $\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f(x,y) , dx , dy = 1$ (volumen total igual a 1)
> 3. Para cualquier regi√≥n $A$ en el plano: $$P((X,Y) \in A) = \iint_A f(x,y) , dx , dy$$
> 
> La densidad conjunta describe c√≥mo se distribuye la probabilidad en el plano $(x,y)$.

### 9.3 Distribuciones Marginales

> [!info] Definici√≥n
> Las **distribuciones marginales** son las distribuciones de cada variable individual, obtenidas "sumando" o "integrando" sobre la otra variable:
> 
> **Caso discreto**:
> 
> - $f_X(x) = \sum_{y} f(x,y)$ (distribuci√≥n marginal de $X$)
> - $f_Y(y) = \sum_{x} f(x,y)$ (distribuci√≥n marginal de $Y$)
> 
> **Caso continuo**:
> 
> - $f_X(x) = \int_{-\infty}^{+\infty} f(x,y) , dy$ (densidad marginal de $X$)
> - $f_Y(y) = \int_{-\infty}^{+\infty} f(x,y) , dx$ (densidad marginal de $Y$)
> 
> Las marginales nos dan informaci√≥n sobre cada variable por separado, ignorando la otra.

### 9.4 Independencia

> [!info] Definici√≥n
> Dos variables aleatorias $X$ e $Y$ son **independientes** si y solo si su distribuci√≥n conjunta se puede factorizar como el producto de sus marginales:
> 
> $$f(x,y) = f_X(x) \cdot f_Y(y) \quad \text{para todo par } (x,y)$$
> 
> **Interpretaci√≥n**: Conocer el valor de una variable no proporciona informaci√≥n sobre la otra.
> 
> **Consecuencias de la independencia**:
> 
> - $P(X=x, Y=y) = P(X=x) \cdot P(Y=y)$ (caso discreto)
> - $E(XY) = E(X) \cdot E(Y)$
> - $Var(X+Y) = Var(X) + Var(Y)$
> - $Cov(X,Y) = 0$ (pero lo contrario no siempre es cierto)

### 9.5 Esperanza Conjunta

> [!info] Definici√≥n
> Para una funci√≥n $g(X,Y)$ de dos variables aleatorias:
> 
> **Caso discreto**: $$E[g(X,Y)] = \sum_{x} \sum_{y} g(x,y) \cdot f(x,y)$$
> 
> **Caso continuo**: $$E[g(X,Y)] = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x,y) \cdot f(x,y) , dx , dy$$
> 
> **Caso particular importante**: $$E(XY) = \sum_{x} \sum_{y} xy \cdot f(x,y) \quad \text{(discreto)}$$ $$E(XY) = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} xy \cdot f(x,y) , dx , dy \quad \text{(continuo)}$$

### 9.6 Covarianza

> [!info] Definici√≥n
> La **covarianza** mide la relaci√≥n lineal entre dos variables aleatorias:
> 
> $$Cov(X,Y) = E[(X-\mu_X)(Y-\mu_Y)] = E(XY) - E(X)E(Y)$$
> 
> **Interpretaci√≥n**:
> 
> - $Cov(X,Y) > 0$: Relaci√≥n positiva (cuando $X$ aumenta, $Y$ tiende a aumentar)
> - $Cov(X,Y) < 0$: Relaci√≥n negativa (cuando $X$ aumenta, $Y$ tiende a disminuir)
> - $Cov(X,Y) = 0$: No hay relaci√≥n lineal (puede haber relaci√≥n no lineal)

> [!success] Propiedades de la Covarianza
> 
> 1. $Cov(X, a) = 0$ (la covarianza con una constante es cero)
> 2. $Cov(X, X) = Var(X)$ (la covarianza de una variable consigo misma es su varianza)
> 3. $Cov(X, Y) = Cov(Y, X)$ (simetr√≠a)
> 4. $Cov(aX, bY) = ab \cdot Cov(X, Y)$ (factorizaci√≥n de constantes)
> 5. $Cov(X+a, Y+b) = Cov(X, Y)$ (invarianza ante traslaciones)
> 6. $Cov(X+Y, Z) = Cov(X, Z) + Cov(Y, Z)$ (linealidad)
> 7. $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)$
> 8. Si $X$ e $Y$ son independientes, entonces $Cov(X,Y) = 0$ (pero no viceversa)

### 9.7 Coeficiente de Correlaci√≥n

> [!info] Definici√≥n
> El **coeficiente de correlaci√≥n** es una versi√≥n estandarizada de la covarianza que siempre est√° entre -1 y 1:
> 
> $$\rho_{X,Y} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}$$
> 
> donde $\sigma_X = \sqrt{Var(X)}$ y $\sigma_Y = \sqrt{Var(Y)}$ son las desviaciones est√°ndar.
> 
> **Propiedades**:
> 
> - $-1 \leq \rho_{X,Y} \leq 1$
> - $\rho_{X,Y} = 1$: Relaci√≥n lineal perfecta positiva ($Y = aX + b$ con $a > 0$)
> - $\rho_{X,Y} = -1$: Relaci√≥n lineal perfecta negativa ($Y = aX + b$ con $a < 0$)
> - $\rho_{X,Y} = 0$: No hay relaci√≥n lineal
> - $|\rho_{X,Y}|$ cercano a 1: Relaci√≥n lineal fuerte
> - $|\rho_{X,Y}|$ cercano a 0: Relaci√≥n lineal d√©bil o inexistente
> 
> **Importante**: El coeficiente de correlaci√≥n mide solo relaciones **lineales**. Puede ser cero incluso si existe una relaci√≥n no lineal fuerte.

---

## 10. Resumen de F√≥rmulas

> [!note] Resumen de distribuciones discretas

| Distribuci√≥n      | Notaci√≥n     | Par√°metros | $P(X = x)$                                          | $E(X)$         | $Var(X)$                                            |
| ----------------- | ------------ | ---------- | --------------------------------------------------- | -------------- | --------------------------------------------------- |
| Binomial          | $B(n, p)$    | $n, p$     | $\binom{n}{x}p^x(1-p)^{n-x}$                        | $np$           | $np(1-p)$                                           |
| Binomial Negativa | $BN(k, p)$   | $k, p$     | $\binom{x-1}{k-1}p^k(1-p)^{x-k}$                    | $\frac{k}{p}$  | $\frac{k(1-p)}{p^2}$                                |
| Geom√©trica        | $Geo(p)$     | $p$        | $p(1-p)^{x-1}$                                      | $\frac{1}{p}$  | $\frac{1-p}{p^2}$                                   |
| Poisson           | $P(\lambda)$ | $\lambda$  | $\frac{\lambda^x e^{-\lambda}}{x!}$                 | $\lambda$      | $\lambda$                                           |
| Hipergeom√©trica   | $H(N,n,k)$   | $N,n,k$    | $\frac{\binom{k}{x}\binom{N-k}{n-x}}{\binom{N}{n}}$ | $\frac{nk}{N}$ | $\frac{N-n}{N-1} \cdot \frac{nk}{N}(1-\frac{k}{N})$ |

> [!note] Resumen de distribuciones continuas

| Distribuci√≥n | Notaci√≥n                | Par√°metros     | $f(x)$                                                                                | $E(X)$                        | $Var(X)$                                               |
| ------------ | ----------------------- | -------------- | ------------------------------------------------------------------------------------- | ----------------------------- | ------------------------------------------------------ |
| Uniforme     | $U(a,b)$                | $a,b$          | $\frac{1}{b-a}$                                                                       | $\frac{a+b}{2}$               | $\frac{(b-a)^2}{12}$                                   |
| Normal       | $N(\mu,\sigma)$         | $\mu,\sigma$   | $\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$                         | $\mu$                         | $\sigma^2$                                             |
| Exponencial  | $Exp(\beta)$            | $\beta$        | $\frac{1}{\beta}e^{-x/\beta}$                                                         | $\beta$                       | $\beta^2$                                              |
| Gamma        | $Gamma(\alpha,\beta)$   | $\alpha,\beta$ | $\frac{1}{\beta^\alpha\Gamma(\alpha)}x^{\alpha-1}e^{-x/\beta}$                        | $\alpha\beta$                 | $\alpha\beta^2$                                        |
| Chi-cuadrado | $\chi^2(v)$             | $v$            | $\frac{1}{2^{v/2}\Gamma(v/2)}x^{v/2-1}e^{-x/2}$                                       | $v$                           | $2v$                                                   |
| Weibull      | $Weibull(\alpha,\beta)$ | $\alpha,\beta$ | $\alpha\beta x^{\beta-1}e^{-\alpha x^\beta}$                                          | Depende de par√°metros         | Depende de par√°metros                                  |
| Beta         | $Beta(\alpha,\beta)$    | $\alpha,\beta$ | $\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}$ | $\frac{\alpha}{\alpha+\beta}$ | $\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$ |

> [!success] Relaci√≥n entre distribuciones

| Distribuci√≥n      | Descripci√≥n                                                       | Cu√°ndo usar                                            |
| ----------------- | ----------------------------------------------------------------- | ------------------------------------------------------ |
| Geom√©trica        | N√∫mero de intentos hasta el **primer** √©xito                      | Buscar el primer evento exitoso                        |
| Binomial Negativa | N√∫mero de intentos hasta el **k-√©simo** √©xito                     | Buscar m√∫ltiples eventos exitosos                      |
| Binomial          | N√∫mero de √©xitos en **n intentos fijos**                          | Contar √©xitos en cantidad fija de ensayos              |
| Poisson           | N√∫mero de eventos por unidad (tiempo/espacio/√°rea)                | Contar eventos raros en un intervalo continuo          |
| Exponencial       | Tiempo entre eventos consecutivos de un proceso Poisson           | Modelar tiempos de espera                              |
| Gamma             | Tiempo hasta el k-√©simo evento en un proceso Poisson              | Suma de k variables exponenciales                      |
| Chi-cuadrado      | Suma de cuadrados de variables normales est√°ndar independientes   | Pruebas de bondad de ajuste, independencia             |
| Normal Est√°ndar   | Estandarizaci√≥n de cualquier variable normal                      | C√°lculo de probabilidades usando tablas                |
| t-Student         | Distribuci√≥n de la media muestral cuando $\sigma$ es desconocida  | Inferencia con muestras peque√±as                       |
| Hipergeom√©trica   | N√∫mero de √©xitos en muestra **sin reemplazo** de poblaci√≥n finita | Muestreo sin reemplazo (probabilidades cambian)        |
| Uniforme          | Todos los valores en un intervalo son igualmente probables        | Cuando no hay preferencia por ning√∫n valor en un rango |
| Beta              | Variable acotada entre 0 y 1 (proporciones, probabilidades)       | Modelar tasas, proporciones, o variables en [0,1]      |
| Weibull           | An√°lisis de confiabilidad con tasas de falla variables            | Estudios de vida √∫til, fallas de materiales            |

> [!tip] Gu√≠a r√°pida de selecci√≥n de distribuci√≥n

**Para variables DISCRETAS**:

- ¬øN√∫mero de √©xitos en n ensayos fijos? ‚Üí **Binomial**
- ¬øEnsayos hasta el primer √©xito? ‚Üí **Geom√©trica**
- ¬øEnsayos hasta el k-√©simo √©xito? ‚Üí **Binomial Negativa**
- ¬øContando eventos raros en tiempo/espacio? ‚Üí **Poisson**
- ¬øMuestreo SIN reemplazo de poblaci√≥n finita? ‚Üí **Hipergeom√©trica**

**Para variables CONTINUAS**:

- ¬øDatos distribuidos sim√©tricamente alrededor de la media? ‚Üí **Normal**
- ¬øTodos los valores igualmente probables en un rango? ‚Üí **Uniforme**
- ¬øTiempo hasta un evento (sin memoria)? ‚Üí **Exponencial**
- ¬øTiempo hasta k eventos? ‚Üí **Gamma**
- ¬øProporci√≥n o tasa entre 0 y 1? ‚Üí **Beta**
- ¬øConfiabilidad o vida √∫til? ‚Üí **Weibull**
- ¬øPruebas estad√≠sticas con muestras peque√±as? ‚Üí **t-Student**
- ¬øPruebas de bondad de ajuste o independencia? ‚Üí **Chi-cuadrado**

> [!warning] Recordatorios importantes

**Conceptos fundamentales**:

1. Las funciones de probabilidad/densidad SIEMPRE son no negativas
2. La suma/integral de una funci√≥n de probabilidad/densidad siempre es 1
3. Para variables continuas: $P(X = x) = 0$ (probabilidad en un punto espec√≠fico)
4. La varianza NUNCA es negativa
5. El valor esperado S√ç puede ser negativo (si la variable toma valores negativos)

**Propiedades clave**:

- $E(aX + b) = aE(X) + b$ (linealidad de la esperanza)
- $Var(aX + b) = a^2 Var(X)$ (la constante aditiva no afecta la varianza)
- $E(X + Y) = E(X) + E(Y)$ (siempre, incluso si no son independientes)
- $Var(X + Y) = Var(X) + Var(Y)$ (SOLO si son independientes)
- Si $X$ e $Y$ son independientes: $E(XY) = E(X)E(Y)$ y $Cov(X,Y) = 0$

**Diferencias cr√≠ticas**:

- **Binomial vs Hipergeom√©trica**: Binomial usa muestreo CON reemplazo (probabilidades constantes), Hipergeom√©trica usa muestreo SIN reemplazo (probabilidades cambian)
- **Poisson vs Exponencial**: Poisson cuenta EVENTOS en tiempo fijo, Exponencial mide TIEMPO entre eventos
- **Normal vs t-Student**: Normal cuando $\sigma$ es conocida o n grande, t-Student cuando $\sigma$ es desconocida y n peque√±a
- **Geom√©trica vs Binomial Negativa**: Geom√©trica busca el PRIMER √©xito (k=1), Binomial Negativa busca el k-√âSIMO √©xito

**Verificaciones antes de aplicar un modelo**:

- ¬øLos ensayos son independientes?
- ¬øLa probabilidad es constante?
- ¬øHay reemplazo o no?
- ¬øLa poblaci√≥n es finita o infinita?
- ¬øSe cuenta eventos o se mide tiempo?
- ¬øCu√°l es el n√∫mero fijo: ensayos o √©xitos?

---

## 11. F√≥rmulas √ötiles Adicionales

> [!note] F√≥rmulas de probabilidad para distribuci√≥n normal

**Estandarizaci√≥n**: $$Z = \frac{X - \mu}{\sigma}$$

**Probabilidades comunes** (Regla emp√≠rica):

- $P(\mu - \sigma \leq X \leq \mu + \sigma) \approx 0.68$
- $P(\mu - 2\sigma \leq X \leq \mu + 2\sigma) \approx 0.95$
- $P(\mu - 3\sigma \leq X \leq \mu + 3\sigma) \approx 0.997$

**C√°lculo de probabilidades**: $$P(a < X < b) = \Phi\left(\frac{b-\mu}{\sigma}\right) - \Phi\left(\frac{a-\mu}{\sigma}\right)$$

donde $\Phi(z)$ es la funci√≥n de distribuci√≥n acumulada de la normal est√°ndar.

> [!note] F√≥rmulas para distribuciones conjuntas

**Probabilidad condicional**: $$f_{X|Y}(x|y) = \frac{f(x,y)}{f_Y(y)}$$

**Esperanza condicional**: $$E(X|Y=y) = \sum_x x \cdot f_{X|Y}(x|y) \quad \text{(discreto)}$$ $$E(X|Y=y) = \int_{-\infty}^{+\infty} x \cdot f_{X|Y}(x|y) , dx \quad \text{(continuo)}$$

**Varianza de suma**: $$Var(aX + bY) = a^2Var(X) + b^2Var(Y) + 2abCov(X,Y)$$

**Para variables independientes**: $$Var(X_1 + X_2 + \cdots + X_n) = Var(X_1) + Var(X_2) + \cdots + Var(X_n)$$

> [!note] Aproximaciones √∫tiles

**Binomial a Normal** (cuando $n$ es grande): Si $X \sim B(n,p)$ y $np \geq 5$ y $n(1-p) \geq 5$: $$X \approx N(np, \sqrt{np(1-p)})$$

**Binomial a Poisson** (cuando $n$ es grande y $p$ es peque√±a): Si $X \sim B(n,p)$ y $n \geq 20$, $p \leq 0.05$, y $np < 10$: $$X \approx Poisson(\lambda = np)$$

**Poisson a Normal** (cuando $\lambda$ es grande): Si $X \sim Poisson(\lambda)$ y $\lambda \geq 10$: $$X \approx N(\lambda, \sqrt{\lambda})$$

> [!warning] Importante
> Recuerda que estas f√≥rmulas y distribuciones son herramientas para modelar la realidad. Siempre verifica que se cumplan los supuestos del modelo antes de aplicarlo. Un modelo incorrecto puede llevar a conclusiones err√≥neas, incluso si los c√°lculos est√°n bien hechos.
